{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Twin Fairways\n",
    "WIP to use the OpenTNSim engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baart_f/.virtualenvs/main/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning:\n",
      "\n",
      "The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import dtv_backend.berthing\n",
    "\n",
    "# the simpy processes and objects\n",
    "import dtv_backend.compat\n",
    "\n",
    "# library to load the fairway information network\n",
    "import dtv_backend.fis\n",
    "import dtv_backend.network\n",
    "import dtv_backend.network.network_utilities\n",
    "import dtv_backend.postprocessing\n",
    "import dtv_backend.simple\n",
    "import dtv_backend.simulate\n",
    "import geojson\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import simpy\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "# opentnsim import\n",
    "from opentnsim import core\n",
    "\n",
    "# reload for debugging purposes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "logger = logging.getLogger(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "You can define your input in a json configuration file. The relevant parts are sites, fleet and climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example input\n",
    "with open(\"config.geojson\") as f:\n",
    "    config = geojson.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate with ``v3_run``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v3_simulate(config):\n",
    "    result = dtv_backend.simulate.v3_run(config)\n",
    "    env = result['env']\n",
    "    logbook = result['operator'].logbook\n",
    "    response = {\n",
    "        \"log\": logbook,\n",
    "        \"config\": config,\n",
    "        \"env\": {\n",
    "            \"epoch\": env.epoch.timestamp(),\n",
    "            \"epoch_iso\": env.epoch.isoformat(),\n",
    "            \"now\": env.epoch,\n",
    "            \"now_iso\": datetime.datetime.fromtimestamp(env.now).isoformat(),\n",
    "        },\n",
    "    }\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baart_f/src/digitaltwin-waterway/dtv_backend/dtv_backend/fis.py:111: ShapelyDeprecationWarning:\n",
      "\n",
      "The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = v3_simulate(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "result = dtv_backend.simulate.v3_run(config)\n",
    "\n",
    "log_df = pd.DataFrame(result[\"operator\"].logbook)\n",
    "log_df[\"actor_name\"] = log_df[\"Meta\"].apply(lambda x: x[\"actor\"].name)\n",
    "log_df[\"actor_type\"] = log_df[\"Meta\"].apply(lambda x: type(x[\"actor\"]).__name__)\n",
    "log_df[\"state\"] = log_df[\"Meta\"].apply(lambda x: x[\"state\"])\n",
    "log_df[\"description\"] = log_df[\"Meta\"].apply(lambda x: x[\"description\"])\n",
    "\n",
    "# rename to these columns\n",
    "columns = [\n",
    "    \"Start\",\n",
    "    \"Stop\",\n",
    "    \"Name\",\n",
    "    \"Description\",\n",
    "    \"Actor\",\n",
    "    \"Actor type\",\n",
    "    \"Geometry\",\n",
    "]\n",
    "pivot_df = pd.DataFrame(\n",
    "    # the pivot creates a multi-index, pick to create a single index\n",
    "    log_df.pivot(index=\"ActivityID\", columns=\"state\")[\n",
    "        [\n",
    "            (\"Timestamp\", \"START\"),\n",
    "            (\"Timestamp\", \"STOP\"),\n",
    "            (\"Message\", \"START\"),\n",
    "            (\"description\", \"START\"),\n",
    "            (\"actor_name\", \"START\"),\n",
    "            (\"actor_type\", \"START\"),\n",
    "            (\"geometry\", \"START\"),\n",
    "        ]\n",
    "    ].values,\n",
    "    columns=columns,\n",
    ")\n",
    "\n",
    "pivot_df[\"Start Timestamp\"] = pivot_df[\"Start\"].values.astype(np.int64) // 10**9\n",
    "pivot_df[\"Stop Timestamp\"] = pivot_df[\"Stop\"].values.astype(np.int64) // 10**9\n",
    "\n",
    "export_columns = [*columns, \"Start Timestamp\", \"Stop Timestamp\"]\n",
    "pivot_df[\"Start\"] = pivot_df[\"Start\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "pivot_df[\"Stop\"] = pivot_df[\"Stop\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# make geometry consistent\n",
    "geometry = pivot_df[\"Geometry\"].apply(\n",
    "    lambda x: shapely.geometry.shape(x)\n",
    "    if (hasattr(x, \"geom_type\") or isinstance(x, dict))\n",
    "    else None\n",
    ")\n",
    "pivot_df['Geometry'] = geometry\n",
    "pivot_df = gpd.GeoDataFrame(pivot_df[export_columns], geometry='Geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = pivot_df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type LineString is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m log_json \u001b[38;5;241m=\u001b[39m \u001b[43mdtv_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _ \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(log_json)\n",
      "File \u001b[0;32m~/src/digitaltwin-waterway/dtv_backend/dtv_backend/postprocessing.py:89\u001b[0m, in \u001b[0;36mlog2json\u001b[0;34m(log_df)\u001b[0m\n\u001b[1;32m     83\u001b[0m geometry \u001b[38;5;241m=\u001b[39m pivot_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: shapely\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeom_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m))\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     88\u001b[0m pivot_df \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pivot_df[export_columns], geometry\u001b[38;5;241m=\u001b[39mgeometry)\n\u001b[0;32m---> 89\u001b[0m json_str \u001b[38;5;241m=\u001b[39m \u001b[43mpivot_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(json_str)\n",
      "File \u001b[0;32m~/.virtualenvs/main/lib/python3.9/site-packages/geopandas/geodataframe.py:749\u001b[0m, in \u001b[0;36mGeoDataFrame.to_json\u001b[0;34m(self, na, show_bbox, drop_id, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_bbox\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;124;03m    Returns a GeoJSON representation of the ``GeoDataFrame`` as a string.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_geo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_bbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type LineString is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(resp['log'])\n",
    "log_json = dtv_backend.postprocessing.log2json(df)\n",
    "_ = json.dumps(log_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
